type="text")
re <- plm(data = nlswork_clean, ln_wage ~ union +
collgrad +age +agesq +tenure +tensq +
not_smsa +south +c_city, model="random",
index=c("idcode", "year"))
# summary(re)
re_robust <- coeftest(re, function(x) vcovHC(x, type = 'sss'))
stargazer(pols,pols_robust,re,re_robust,title = "Regression analysis",
model.numbers = FALSE,
column.labels = c("Pooled","Pooled (cluster)","RE","RE (cluster"),
label = "regressions",
table.placement = "!ht",
notes.append = TRUE,
notes.align="l",
notes="Standard errors in parentheses.",
header = FALSE,
no.space = TRUE,
covariate.labels = c("Union","College Graduate","Age","Age sqrd.",
"Tenure","Tenure sqrd.","Not SMSA","South","City"),
omit = c("Constant"),
omit.stat = c("adj.rsq","f","ser"),
digits = 3,
digits.extra = 5,
omit.yes.no = c("Constant",""),
dep.var.caption="",
dep.var.labels.include = FALSE,
style = "qje",
type="text")
fe <- plm(data = nlswork_clean, ln_wage ~ union +
collgrad +age +agesq +tenure +tensq +
not_smsa +south +c_city, model="within", index=c("idcode", "year"))
summary(fe)
stargazer(pols,re,fe,title = "Regression analysis",
model.numbers = FALSE,
column.labels = c("Pooled","RE","FE"),
label = "regressions",
table.placement = "!ht",
notes.append = TRUE,
notes.align="l",
notes="Standard errors in parentheses.",
header = FALSE,
no.space = TRUE,
covariate.labels = c("Union","College","Age","Age sqrd.","Tenure",
"Tenure sqrd.","Not SMSA","South","City"),
omit = c("Constant"),
omit.stat = c("adj.rsq","f","ser"),
digits = 6,
digits.extra = 7,
omit.yes.no = c("Constant",""),
dep.var.caption="",
dep.var.labels.include = FALSE,
style = "qje",
type="text")
# generate fixed-effects
# nlswork_clean$specific_effects <- fixef(fe)
# *Q3.1*
fe_robust <- coeftest(fe, function(x) vcovHC(x, type = 'sss'))
ols_0 <- lm(data = nlswork_clean, ln_wage ~ union +
age +agesq +tenure +tensq +
not_smsa +south +c_city)
stargazer(ols_0,fe,fe_robust,title = "Regression analysis",
model.numbers = FALSE,
column.labels = c("OLS","FE","FE (cluster)"),
label = "regressions",
table.placement = "!ht",
notes.append = TRUE,
notes.align="l",
notes="Standard errors in parentheses.",
header = FALSE,
no.space = TRUE,
covariate.labels = c("Union","Age","Age sqrd.","Tenure",
"Tenure sqrd.","Not SMSA","South","City"),
omit = c("Constant"),
omit.stat = c("adj.rsq","f","ser"),
digits = 6,
digits.extra = 7,
omit.yes.no = c("Constant",""),
dep.var.caption="",
dep.var.labels.include = FALSE,
style = "qje",
type="text")
# //Final slide 35
#
# *Q4*
fe_0 <- plm(data = nlswork_clean, ln_wage ~ union +
age +agesq +tenure +tensq +
not_smsa +south +c_city, model="within", index=c("idcode", "year"))
re_0 <- plm(data = nlswork_clean, ln_wage ~ union +
age +agesq +tenure +tensq +
not_smsa +south +c_city, model="random", index=c("idcode", "year"))
phtest(fe_0, re_0)
install.packages("tinytex")
version
version
# Instale e carregue os pacotes necessários
install.packages(c("ggplot2", "maps", "mapdata"))
library(ggplot2)
library(maps)
library(mapdata)
# Obtenha o mapa mundial
world_map <- map_data("world")
# Exemplo de dados
set.seed(123) # para reproduzibilidade
data <- data.frame(
country = c("Brazil", "United States", "China", "Russia", "India", "Australia"),
value = runif(6, min = 1, max = 100) # Simulação de valores aleatórios
)
# Mapeie o nome dos países para o formato usado pelo pacote 'maps'
data$country <- tolower(data$country)
# Junte os dados com o mapa
world_map$value <- data$value[match(world_map$region, data$country)]
# Desenhe o mapa
ggplot() +
geom_polygon(data = world_map, aes(x = long, y = lat, group = group, fill = value), color = "black") +
scale_fill_gradient(low = "blue", high = "red", na.value = "grey50") +
coord_quickmap() +
labs(fill = "Value") +
theme_minimal() +
theme(legend.position = "bottom")
world_map <- map_data("world")
View(world_map)
View(data)
View(data)
world_map <- map_data("world")
View(data)
View(world_map)
View(world_map)
install.packages(c("broom", "bslib", "cachem", "checkmate", "clock", "collapse", "curl", "DEoptimR", "dplyr", "DT", "emmeans", "evaluate", "fontawesome", "fs", "future.apply", "gargle", "googledrive", "googlesheets4", "Hmisc", "httpuv", "httr", "jsonlite", "knitr", "later", "lme4", "markdown", "matrixStats", "miscTools", "mvtnorm", "norm", "parallelly", "plm", "pROC", "processx", "ps", "quantmod", "quantreg", "RcppArmadillo", "recipes", "rlang", "rmarkdown", "robustbase", "sass", "scatterplot3d", "sys", "testthat", "tinytex", "tseries", "tzdb", "vctrs", "viridis", "viridisLite", "vroom", "waldo", "xfun", "xml2", "xts", "zip", "zoo"))
version
Version
version
#Group 3
#Reshape and Merge
library(readxl)
median_value_per_m2<- as.data.frame(read_excel("C:\\Users\\Joana Cima\\\Desktop\group3_SIA\\MedianValuePer_m2_2016_2020.xlsx",
#Group 3
#Reshape and Merge
library(readxl)
median_value_per_m2<- as.data.frame(read_excel("C:\\Users\\Joana Cima\\Desktop\group3_SIA\\MedianValuePer_m2_2016_2020.xlsx",
library(readxl)
median_value_per_m2<- as.data.frame(read_excel("C:\\Users\\Joana Cima\\Desktop\\group3_SIA\\MedianValuePer_m2_2016_2020.xlsx",
sheet = "Table", na = " "))
#Group 3
#Reshape and Merge
library(readxl)
median_value_per_m2<- as.data.frame(read_excel("C:/Users/Joana Cima/Desktop/group3_SIA/MedianValuePer_m2_2016_2020.xlsx",
sheet = "Table", na = " "))
#Group 3
#Reshape and Merge
library(readxl)
median_value_per_m2<- as.data.frame(read_excel("C:/Users/Joana Cima/Desktop/group3_SIA/MedianValuePer_m2_2016_2020.xlsx",
sheet = "Table", na = " "))
#Group 3
#Reshape and Merge
library(readxl)
median_value_per_m2<- as.data.frame(read_excel("C:\Users\Joana Cima\Desktop\group3_SIA\MedianValuePer_m2_2016_2020.xlsx",
library(readxl)
MedianValuePer_m2_2016_2020 <- read_excel("C:/Users/Joana Cima/Desktop/group3_SIA/MedianValuePer_m2_2016_2020.xls",
sheet = "Table", range = "A9:K353")
View(MedianValuePer_m2_2016_2020)
library(readxl)
MedianValuePer_m2_2016_2020_v2 <- read_excel("C:/Users/Joana Cima/Desktop/group3_SIA/bd_clean/MedianValuePer_m2_2016_2020_v2.xls",
sheet = "Table_v2", range = "A7:G351")
View(MedianValuePer_m2_2016_2020_v2)
library(readxl)
db_MedianValuePer_m2_2016_2020 <- as.data.frame(read_excel("C:/Users/Joana Cima/Desktop/group3_SIA/bd_clean/MedianValuePer_m2_2016_2020_v2.xls",
sheet = "Table_v2", range = "A7:G351"))
View(db_MedianValuePer_m2_2016_2020)
names(db_MedianValuePer_m2_2016_2020)[1] <- "location"
names(db_MedianValuePer_m2_2016_2020)[2] <- "location_code"
View(db_MedianValuePer_m2_2016_2020)
library(readxl)
db_MedianValuePer_m2_2016_2020 <- as.data.frame(read_excel("C:/Users/Joana Cima/Desktop/group3_SIA/bd_clean/MedianValuePer_m2_2016_2020_v2.xls",
sheet = "Table_v2", range = "A7:G351"))
View(db_MedianValuePer_m2_2016_2020)
## 1.2 Rename first and second columns
names(db_MedianValuePer_m2_2016_2020)[1] <- "location"
names(db_MedianValuePer_m2_2016_2020)[2] <- "location_code"
View(db_MedianValuePer_m2_2016_2020)
## 1.3 Reshape
library(tidyverse)
new_database<- db_MedianValuePer_m2_2016_2020 %>%
gather(key = "year", value = "Poverty risk", -location)
View(new_database)
library(tidyverse)
new_database<- db_MedianValuePer_m2_2016_2020 %>%
gather(key = "year", value = "MedianValueper_m2")
View(new_database)
View(MedianValuePer_m2_2016_2020_v2)
new_database= reshape(db_MedianValuePer_m2_2016_2020,
idvar= "location",
varying = list(3:7),
timevar= "year",
times = c("2020","2019", "2018", "2017", "2016"),
new.row.names= 1:10000,
direction = "long"
)
names(db_MedianValuePer_m2_2016_2020)[1] <- "location"
names(db_MedianValuePer_m2_2016_2020)[2] <- "location_code"
View(db_MedianValuePer_m2_2016_2020)
View(MedianValuePer_m2_2016_2020_v2)
View(MedianValuePer_m2_2016_2020)
#Group 3
#Reshape and Merge (5 bases de dados)
# 1 Database MedianValuePer_m2_2016_2020_v2.xls
## 1.1 Import "MedianValuePer_m2_2016_2020_v2.xls" - Sheet - Table_v2
library(readxl)
db_MedianValuePer_m2_2016_2020 <- as.data.frame(read_excel("C:/Users/Joana Cima/Desktop/group3_SIA/bd_clean/MedianValuePer_m2_2016_2020_v2.xls",
sheet = "Table_v2", range = "A7:G351"))
View(db_MedianValuePer_m2_2016_2020)
## 1.2 Rename first and second columns
names(db_MedianValuePer_m2_2016_2020)[1] <- "location"
names(db_MedianValuePer_m2_2016_2020)[2] <- "location_code"
View(db_MedianValuePer_m2_2016_2020)
View(MedianValuePer_m2_2016_2020_v2)
View(MedianValuePer_m2_2016_2020)
View(db_MedianValuePer_m2_2016_2020)
new_database= reshape(db_MedianValuePer_m2_2016_2020,
idvar= "location",
varying = list(3:7),
timevar= "year",
times = c("2020","2019", "2018", "2017", "2016"),
new.row.names= 1:10000,
direction = "long"
)
#Group 3
#Reshape and Merge (5 bases de dados)
rm(list=ls())
# 1 Database MedianValuePer_m2_2016_2020_v2.xls
## 1.1 Import "MedianValuePer_m2_2016_2020_v2.xls" - Sheet - Table_v2
library(readxl)
db_MedianValuePer_m2_2016_2020 <- as.data.frame(read_excel("C:/Users/Joana Cima/Desktop/group3_SIA/bd_clean/MedianValuePer_m2_2016_2020_v2.xls",
sheet = "Table_v2", range = "A7:G351"))
View(db_MedianValuePer_m2_2016_2020)
## 1.2 Rename first and second columns
names(db_MedianValuePer_m2_2016_2020)[1] <- "location"
names(db_MedianValuePer_m2_2016_2020)[2] <- "location_code"
View(db_MedianValuePer_m2_2016_2020)
## 1.3 Reshape
new_database= reshape(db_MedianValuePer_m2_2016_2020,
idvar= "location",
varying = list(3:7),
timevar= "year",
times = c("2020","2019", "2018", "2017", "2016"),
new.row.names= 1:10000,
direction = "long"
)
View(new_database)
new_database= reshape(db_MedianValuePer_m2_2016_2020,
idvar= "location",
varying = list(3:7),
times = c("2020","2019", "2018", "2017", "2016"),
new.row.names= 1:10000,
direction = "long"
)
View(new_database)
new_database= reshape(db_MedianValuePer_m2_2016_2020,
idvar= "location",
varying = list(3:7),
timevar= "year",
times = c("2020","2019", "2018", "2017", "2016"),
new.row.names= 1:10000,
direction = "long"
)
#Group 3
#Reshape and Merge (5 bases de dados)
rm(list=ls())
# 1 Database MedianValuePer_m2_2016_2020_v2.xls
## 1.1 Import "MedianValuePer_m2_2016_2020_v2.xls" - Sheet - Table_v2
library(readxl)
db_MedianValuePer_m2_2016_2020 <- as.data.frame(read_excel("C:/Users/Joana Cima/Desktop/group3_SIA/bd_clean/MedianValuePer_m2_2016_2020_v2.xls",
sheet = "Table_v2", range = "A7:G351"))
View(db_MedianValuePer_m2_2016_2020)
## 1.2 Rename first and second columns
names(db_MedianValuePer_m2_2016_2020)[1] <- "location"
names(db_MedianValuePer_m2_2016_2020)[2] <- "location_code"
View(db_MedianValuePer_m2_2016_2020)
## 1.3 Reshape
new_database= reshape(db_MedianValuePer_m2_2016_2020,
idvar= "location",
varying = list(3:7),
timevar= "year",
v.names = "medianvalue_per_m2",
times = c("2020","2019", "2018", "2017", "2016"),
new.row.names= 1:10000,
direction = "long"
)
View(new_database)
install.packages(c("askpass", "bslib", "checkmate", "collapse", "cpp11", "curl", "dbplyr", "DEoptimR", "digest", "dplyr", "DT", "evaluate", "fansi", "fontawesome", "forecast", "fs", "gargle", "ggplot2", "gtable", "haven", "htmlTable", "htmltools", "httr", "jsonlite", "knitr", "labeling", "lava", "lifecycle", "lme4", "lubridate", "magick", "markdown", "MatrixModels", "matrixStats", "minqa", "openssl", "pkgload", "plyr", "prettyunits", "pROC", "processx", "promises", "purrr", "quantmod", "quantreg", "ragg", "rbibutils", "Rcpp", "RcppArmadillo", "RcppEigen", "Rdpack", "readxl", "rematch", "rlang", "rmarkdown", "rprojroot", "rstudioapi", "sass", "stringi", "stringr", "systemfonts", "testthat", "textshaping", "tinytex", "utf8", "uuid", "vctrs", "viridis", "vroom", "waldo", "withr", "xfun", "xml2"))
# Limpar o ambiente de trabalho
rm(list = ls())
# Definir o diretório de trabalho
setwd("C:\Users\Joana Cima\Desktop\aulas_EEG\análisededados\PanelData_Econometrics")
# Limpar o ambiente de trabalho
rm(list = ls())
# Definir o diretório de trabalho
setwd("C:\\Users\\Joana Cima\\Desktop\\aulas_EEG\\análisededados\\PanelData_Econometrics")
install.packages("haven")
# Clean the work environment
rm(list = ls())
# Set the working directory
setwd("C:\\Users\\Joana Cima\\Desktop\\aulas_EEG\\análisededados\\PanelData_Econometrics")
# Import the data
# install.packages("haven")
library(haven)
dados <- read_dta("mus08psidextract.dta")
# View tha variables
names(data)
library(haven)
data <- read_dta("mus08psidextract.dta")
# View tha variables
names(data)
# Descrever os dados
summary(data)
# Descriptive statistics
summary(data)
library(plm)
# Define data as panel data
pdata <- pdata.frame(data, index = c("id", "t"))
#1. Data Preparation and Reading
# Clean the work environment
rm(list = ls())
# Set the working directory
setwd("C:\\Users\\Joana Cima\\Desktop\\aulas_EEG\\análisededados\\PanelData_Econometrics")
# Import the data
# install.packages("haven")
library(haven)
data <- read_dta("mus08psidextract.dta")
#2. Data Description:
# View tha variables
names(data)
# Descriptive statistics
summary(data)
# install.packages("plm")
library(plm)
#3. Panel data setup
# Define data as panel data
pdata <- pdata.frame(data, index = c("id", "t"))
#4. Econometric analysis
#POLS with Robust Standard Errors:
library(lmtest)
library(sandwich)
pols1 <- lm(lwage ~ fem + blk + ed + ms + exp + exp2 + occ + ind + south + smsa + union, data = pdata)
coeftest(pols1, vcov = vcovHC(pols1, type = "HC1"))
fe1 <- plm(lwage ~ fem + blk + ed + ms + exp + exp2 + occ + ind + south + smsa + union, data = pdata, model = "within")
summary(fe1)
fe1 <- plm(lwage ~ fem + blk + ed + ms + exp + exp2 + occ + ind + south + smsa + union, data = pdata, model = "within")
fe1 <- plm(lwage ~ ms + exp + exp2 + occ + ind + south + smsa + union, data = pdata, model = "within")
summary(fe1)
fe1 <- plm(lwage ~ ms + exp + exp2 + occ + ind + south + smsa + union, data = pdata, model = "within")
summary(fe1)
phtest(pols1, re1)
pdata <- pdata.frame(data, index = c("id", "t"))
#4. Econometric analysis
#POLS with Robust Standard Errors:
library(lmtest)
library(sandwich)
pols1 <- lm(lwage ~ fem + blk + ed + ms + exp + exp2 + occ + ind + south + smsa + union, data = pdata)
coeftest(pols1, vcov = vcovHC(pols1, type = "HC1"))
# Random effects
re1 <- plm(lwage ~ fem + blk + ed + ms + exp + exp2 + occ + ind + south + smsa + union, data = pdata, model = "random")
summary(re1)
# LM Test for Unobserved Effects
fe1 <- plm(lwage ~ fem + blk + ed + ms + exp + exp2 + occ + ind + south + smsa + union, data = pdata, model = "within")
summary(fe1)
fe1 <- plm(lwage ~ ms + exp + exp2 + occ + ind + south + smsa + union, data = pdata, model = "within")
summary(fe1)
phtest(pols1, re1)
pols1 <- plm(lwage ~ fem + blk + ed + ms + exp + exp2 + occ + ind + south + smsa + union, data = pdata, model = "pooling")
summary(pols1)
coeftest(pols1, vcov = vcovHC(pols1, type = "HC1"))
# LM Test for Unobserved Effects
phtest(pols1, re1)
hausman(fe1, re1)
phtest(fe1, re1)
library(lmtest)
bptest(fe1)
pbgtest(fe1)
coeftest(fe_model, vcov = vcovHC(fe_model, type = "HC1", cluster = "group"))
coeftest(fe1, vcov = vcovHC(fe_model, type = "HC1", cluster = "group"))
summary(coeftest)
coeftest(fe1, vcov = vcovHC(fe_model, type = "HC1", cluster = "id"))
coeftest(fe1, vcov = vcovHC(fe_model, type = "HC1", cluster = "id"))
coeftest(fe1, vcov = vcovHC(fe1, type = "HC1", cluster = "id"))
coeftest(fe1, vcov = vcovHC(fe1, type = "HC1", cluster = ~id))
coeftest(fe1, vcov = vcovHC(fe1, type = "HC1", cluster = "group", group = index(pdata)[, "id"]))
summary(coeftest)
stargazer(pols1, fe1, re1, type = "text")
library(stargazer)
stargazer(pols1, fe1, re1, type = "text")
pols1 <- plm(lwage ~ fem + blk + ed + ms + exp + exp2 + occ + ind + south + smsa + union, data = pdata, model = "pooling")
coeftest(pols1, vcov = vcovHC(pols1, type = "HC1"))
pols1_robust <- coeftest(pols1, vcov = vcovHC(pols1, type = "HC1"))
stargazer(pols1, re1, fe1_robust)
stargazer(pols1, re1, fe_robust)
fe_robust <-coeftest(fe1, vcov = vcovHC(fe1, type = "HC1", cluster = "group", group = index(pdata)[, "id"]))
# 7. Export
library(stargazer)
stargazer(pols1, re1, fe_robust)
stargazer(pols1, re1, fe_robust, type = "text")
stargazer(fe_robust, type = "text")
stargazer(fe_robust, type = "text", column.labels = c("FE Robust"))
pols1 <- plm(lwage ~ fem + blk + ed + ms + exp + exp2 + occ + ind + south + smsa + union, data = pdata, model = "pooling")
coeftest(pols1, vcov = vcovHC(pols1, type = "HC1"))
pols_robust <-coeftest(pols_robust, vcov = vcovHC(pols_robust, type = "HC1", cluster = "group", group = index(pdata)[, "id"]))
pols1 <- plm(lwage ~ fem + blk + ed + ms + exp + exp2 + occ + ind + south + smsa + union, data = pdata, model = "pooling")
coeftest(pols1, vcov = vcovHC(pols1, type = "HC1"))
pols_robust <-coeftest(pols1, vcov = vcovHC(pols1, type = "HC1", cluster = "group", group = index(pdata)[, "id"]))
re1 <- plm(lwage ~ fem + blk + ed + ms + exp + exp2 + occ + ind + south + smsa + union, data = pdata, model = "random")
re_robust <-coeftest(re1, vcov = vcovHC(re1, type = "HC1", cluster = "group", group = index(pdata)[, "id"]))
summary(re1)
# 4.2.1 LM Test for Unobserved Effects (POLS vs random effects)
phtest(pols1, re1)
LSDV <- lm(lwage ~ ms + exp + exp2 + occ + ind + south + smsa + union + factor(id), data = pdata)
LSDV <- lm(lwage ~ ms + exp + exp2 + occ + ind + south + smsa + union + factor(id), data = pdata)
summary(LSDV)
fe1 <- plm(lwage ~ ms + exp + exp2 + occ + ind + south + smsa + union, data = pdata, model = "within")
summary(fe1)
LSDV <- lm(lwage ~ ms + exp + exp2 + occ + ind + south + smsa + union + factor(id), data = pdata)
linearHypothesis(LSDV, matchCoefs(LSDV, "factor(id)"))
linearHypothesis(LSDV, matchCoefs(LSDV, "factor(id)"))
linearHypothesis(LSDV, matchCoefs(LSDV, "factor(id)"))
linearHypothesis(LSDV, matchCoefs(LSDV, "factor(id)"))
library("car")
linearHypothesis(LSDV, matchCoefs(LSDV, "factor(id)"))
library(car)
linearHypothesis(LSDV, matchCoefs(LSDV, "factor(id)"))
library(car)
linearHypothesis(LSDV, matchCoefs(LSDV, factor(id)))
library(car)
linearHypothesis(LSDV, matchCoefs(LSDV, id))
LSDV <- lm(lwage ~ ms + exp + exp2 + occ + ind + south + smsa + union + factor(id), data = pdata)
summary(LSDV)
library(car)
linearHypothesis(LSDV, matchCoefs(LSDV, id))
library(car)
linearHypothesis(LSDV, matchCoefs(LSDV, factor(id)))
linearHypothesis(LSDV, matchCoefs(LSDV, "factor(id)"))
anova(pols1, LSDV)
chow.test(pols1, LSDV)
library(lmtest)
chow.test(LSDVm pols1)
chow.test(LSDVm, pols1)
install.packages("strucchange")
library(strucchange)
chow.test(LSDVm, pols1)
chow.test(LSDV, pols1)
anova_result <- anova(LSDV, pols1)
anova(LSDV, pols1)
plmtest(pols1)
plmtest(pols1, type = "bp")
phtest(fe1, re1)
phtest( re1, fe1)
fe1 <- plm(lwage ~ fem + blk + ed + ms + exp + exp2 + occ + ind + south + smsa + union, data = pdata, model = "within")
summary(fe1)
fe1 <- plm(lwage ~ ms + exp + exp2 + occ + ind + south + smsa + union, data = pdata, model = "within")
summary(fe1)
phtest(fe1, re1)
re1 <- plm(lwage ~ ms + exp + exp2 + occ + ind + south + smsa + union, data = pdata, model = "random")
phtest(fe1, re1)
fe_robust <-coeftest(fe1, vcov = vcovHC(fe1, type = "arellano", cluster = "group", group = index(pdata)[, "id"]))
fe_robust <- coeftest(fe1, vcov = vcovHC(fe1, type = "arellano", cluster = "group"))
fe_robust <- coeftest(fe1, vcovHC(fixed, method = "arellano"))
fe_robust <- coeftest(fe1, vcovHC(fe1, method = "arellano"))
summary(fe_robust)
fe_robust
?vcovHAC
?vcovHC
?vcovHC
fe_robust <- coeftest(fe1, vcovHC(fe1, method = "arellano"))
# 7. Export
library(stargazer)
stargazer(fe_robust, type = "text", column.labels = c("FE Robust"))
# 1. Data Preparation and Import
# 1.1 Clean the work environment
rm(list = ls())
# 1.2 Set the working directory
setwd("C:\\Users\\Joana Cima\\Documents\\GitHub\\Panel_models_R")
# 1.3 Import the data
# install.packages("haven")
library(haven)
data <- read_dta("mus08psidextract.dta")
View(data)
pols1 <- plm(lwage ~ fem + blk + ed + ms + exp + exp2 + occ + ind + south + smsa + union, data = pdata, model = "pooling")
# 1. Data Preparation and Import
# 1.1 Clean the work environment
rm(list = ls())
# 1.2 Set the working directory
setwd("C:\\Users\\Joana Cima\\Documents\\GitHub\\Panel_models_R")
# 1.3 Import the data
# install.packages("haven")
library(haven)
data <- read_dta("mus08psidextract.dta")
View(data)
# 2. Data Description:
# 2.1 View tha variables
names(data)
# 2.2 Descriptive statistics
summary(data)
# install.packages("plm")
library(plm)
# 3. Panel data setup
# 3.1 Define data as panel data
pdata <- pdata.frame(data, index = c("id", "t"))
# 4. Econometric analysis
# 4.1 POLS with Robust Standard Errors:
#install.packages("lmtest")
#install.packages("sandwich")
library(lmtest)
library(sandwich)
pols1 <- plm(lwage ~ fem + blk + ed + ms + exp + exp2 + occ + ind + south + smsa + union, data = pdata, model = "pooling")
summary(pols1)
